# ğŸ“š Main Fundamental Concepts of NLP

![NLP Banner](media/NLP_IMAGE.jpg)

A comprehensive guide to the foundational text representation techniques in Natural Language Processing. Understanding these core concepts is essential for anyone venturing into NLP, as they form the building blocks upon which modern Large Language Models (LLMs) and Agentic AI systems are built. These are the fundamental techniques where every NLP journey begins.

## ğŸ¯ Overview

This repository contains an educational resource that explores three essential NLP text representation techniques:

1. **Bag of Words (BoW)** - Simple frequency-based word counting
2. **TF-IDF** - Weighted importance scoring for documents
3. **Word2Vec** - Semantic embeddings capturing meaning and context


## ğŸ“– What You'll Learn

### 1. Bag of Words (BoW)
- How text is converted to numerical vectors
- Vocabulary creation and word counting
- Sparse vector representations
- When to use frequency-based approaches

### 2. TF-IDF (Term Frequency-Inverse Document Frequency)
- Measuring word importance across documents
- Mathematical formula: `TF-IDF(t, d) = TF(t, d) Ã— log(N / n_t)`
- Weighting unique vs. common terms
- Applications in information retrieval

### 3. Word2Vec
- Dense semantic embeddings
- Skip-Gram vs. CBOW architectures
- Vector arithmetic and analogies (`king - man + woman â‰ˆ queen`)
- Context-aware word representations

## ğŸ“ Who Should Use This

This resource is perfect for:

- **Beginners** starting their NLP journey
- **Students** learning text processing fundamentals
- **Data Scientists** refreshing core concepts
- **Educators** teaching NLP basics
- **Developers** building language applications
- **AI Enthusiasts** understanding how LLMs process text

## ğŸ‘¤ Author

**Yasser A. Albogami**


## ğŸŒ Live Page

**Visit:** [https://yasseralbogami.github.io/nlp_fundamentals]([https://yasseralbogami.github.io/nlp_fundamentals/])
